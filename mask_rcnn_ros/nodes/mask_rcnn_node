#!/usr/bin/env python
import os
import threading
from Queue import Queue
import numpy as np
import skimage.io
import cv2
import random
from cv_bridge import CvBridge
import rospy
from sensor_msgs.msg import Image
from sensor_msgs.msg import RegionOfInterest
from std_msgs.msg import UInt8MultiArray

from mask_rcnn_ros import coco
from mask_rcnn_ros import utils
from mask_rcnn_ros import model as modellib
from mask_rcnn_ros import visualize
from mask_rcnn_ros.msg import Result


DEBUG = True
COCO_MODEL_PATH = '/home/padmaja/Downloads/software/Mask_RCNN/mask_rcnn_capsicum_latest.h5'

CLASS_NAMES = ['BG', 'capsicum']
BOX_PADDING = 60

class InferenceConfig(coco.CocoConfig):
    # Set batch size to 1 since we'll be running inference on
    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1
    

class MaskRCNNNode(object):
    
    def __init__(self):
        
        self._cv_bridge = CvBridge()
        config = InferenceConfig()
        config.display()
        
        # True if you want to see the detection as a ros topic
        self._visualization = rospy.get_param('~visualization', True)
        
        # Create model object in inference mode.
        self._model = modellib.MaskRCNN(mode="inference", model_dir="",
                                        config=config)
        # Load weights
        model_path = rospy.get_param('~model_path', COCO_MODEL_PATH)
        
        self._model.load_weights(model_path, by_name=True) #TODO: Check if exclusion is correct as it wont recognize

        self._class_names = rospy.get_param('~class_names', CLASS_NAMES)

        self._last_msg = None
        self._msg_lock = threading.Lock()
        self._image_aquired = False
        self._depth_image = None

        self._class_colors = visualize.random_colors(len(CLASS_NAMES))
        self._publish_rate = rospy.get_param('~publish_rate', 100)
        
        # Publishers and subscribers
        self._result_pub = rospy.Publisher('~result', Result, queue_size=1)
        self.vis_pub = rospy.Publisher('~visualization', Image, queue_size=1)
        sub = rospy.Subscriber('/camera/color/image_raw', Image,
                               self._image_callback, queue_size=1)
        depth_sub = rospy.Subscriber('/camera/depth/image_rect_raw', Image,
                               self._depth_image_callback, queue_size=1)
        
        # Used to save the debug images
        self.count = 1

    def run(self):
    
        rate = rospy.Rate(self._publish_rate)
        while not rospy.is_shutdown():
            if self._msg_lock.acquire(False):
                msg = self._last_msg
                self._image_aquired = True
                self._last_msg = None
                self._msg_lock.release()
            else:
                rate.sleep()
                continue

            if msg is not None:
                # Convert image to a CV format
                np_image = self._cv_bridge.imgmsg_to_cv2(msg, 'bgr8')   
                
                # Run detection          
                results = self._model.detect([np_image], verbose=0)
                
                # Get the result
                result = results[0]

                # Inflated masks are used later to inflate paprika mask and find some commaon 
                # intersection between paprika and the obstructing leave
                inflated_masks = []
                
                # Maks has a default shape of 28 X 28 X 0, if nothing is detected. Make sure soemthing is detected before proceeding.
                if result['masks'].shape[0] > 0:
                    for i in range(result['masks'].shape[2]):
                        inflated_masks.append(self.inflate_mask(result['masks'][:, :, i], 30))
                        
                    result['rois'] = self.build_box_around_rois(result['rois'], np_image.shape)
                    
                    # Visualize results. Only for a person to see. Not required when running on a robot.
                    if self._visualization:
                        vis_image = self._visualize(result, np_image)
                        cv_result = np.zeros(shape=vis_image.shape, dtype=np.uint8)
                        cv2.convertScaleAbs(vis_image, cv_result)
                        image_msg = self._cv_bridge.cv2_to_imgmsg(cv_result, 'bgr8')
                        self.vis_pub.publish(image_msg)
                        if False:
                            # Save debug depth image.
                            for i, (y1, x1, y2, x2) in enumerate(result['rois']):
                                np.savetxt('test_'+str(self.count)+ '.out', self._depth_image, delimiter=',')
                                self.count = self.count + 1

                        
                    # Find depth of paprika covered region. Zero points are thrown out.
                    avg_paprika_depths = self.get_avg_depth_of_mask(result['rois'], result['masks'])
                    
                    # Find and save(?) obstacle mask for only first detection for now.
                    for i, (y1, x1, y2, x2) in enumerate(result['rois']):
                        if i ==0:
                            name = 'green_'+str(self.count)+ '.png'
                            leaf_mask = self.find_leaves(np_image, name, 
                                             avg_paprika_depths[i], self._depth_image, inflated_masks[i]) 
                                             #result['masks'][y1:y2, x1:x2, i])
                            self.count = self.count + 1
    
            rate.sleep()

    def _build_result_msg(self, msg, result):
        result_msg = Result()
        result_msg.header = msg.header
        for i, (y1, x1, y2, x2) in enumerate(result['rois']):
            box = RegionOfInterest()
            box.x_offset = np.asscalar(x1)
            box.y_offset = np.asscalar(y1)
            box.height = np.asscalar(y2 - y1)
            box.width = np.asscalar(x2 - x1)
            result_msg.boxes.append(box)

            class_id = result['class_ids'][i]
            result_msg.class_ids.append(class_id)

            class_name = self._class_names[class_id]
            result_msg.class_names.append(class_name)

            score = result['scores'][i]
            result_msg.scores.append(score)

            mask = Image()
            mask.header = msg.header
            mask.height = result['masks'].shape[0]
            mask.width = result['masks'].shape[1]
            mask.encoding = "mono8"
            mask.is_bigendian = False
            mask.step = mask.width
            mask.data = (result['masks'][:, :, i] * 255).tobytes()
            result_msg.masks.append(mask)
        return result_msg
    
    def build_box_around_rois(self, rois, shape):
        '''
        ROIS are y1, x1, y2, x2
        '''  
        for i in range(len(rois)):
            rois[i][0] = max(0, rois[i][0]-BOX_PADDING)
            rois[i][1] = max(0, rois[i][1]-BOX_PADDING)
            rois[i][2] = min(shape[0]-1, rois[i][2] + BOX_PADDING)
            rois[i][3] = min(shape[1]-1, rois[i][3] + BOX_PADDING)
        return rois
            
    def mask_obstacles(self, rois):
        obstacle_mask = None
        pass
        

    def _visualize(self, result, image):
        from matplotlib.backends.backend_agg import FigureCanvasAgg
        from matplotlib.figure import Figure

        fig = Figure()
        canvas = FigureCanvasAgg(fig)
        axes = fig.gca()
        visualize.display_instances(image, result['rois'], result['masks'],
                                    result['class_ids'], CLASS_NAMES,
                                    result['scores'], ax=axes,
                                    class_colors=self._class_colors)
        fig.tight_layout()
        canvas.draw()
        result = np.fromstring(canvas.tostring_rgb(), dtype='uint8')

        _, _, w, h = fig.bbox.bounds
        result = result.reshape((int(h), int(w), 3))
        return result
    
    
    def get_roi_centers(self, rois):
        centers = []
        for i in range(len(rois)):
            centers.append([(int((rois[i][0] + rois[i][2])/2)),
                (int((rois[i][1] + rois[i][3])/2))])
        return centers
    
    
    def get_avg_depth_of_mask(self, rois, masks):
        avg_depths = []
        # print(masks.shape)
        for i in range(len(rois)):
            depth_image = masks[:,:,i] * self._depth_image
            count_nonz = np.count_nonzero(depth_image)
            if count_nonz >0:
                avg_depths.append(np.sum(depth_image)/count_nonz)
        return avg_depths

    
    def find_leaves(self, img, name, avg_depth, depth_image, inflated_paprika_mask):
        
        '''
        Finds the region which in front of the paprika and are close to the paprika alongwith
        the box enclosing it.
        '''
        
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        # mask of green (36,25,25) ~ (86, 255,255)
        # slice the green
        green_mask = cv2.inRange(hsv, (30, 25, 15), (80, 255,255))
        
        # Slice the area in front of the paprika.
        depth_mask = depth_image < avg_depth
        
        # Slice the green in front of the paprika.
        green_in_front_mask = self.find_common_region_in_masks(green_mask, depth_mask)
        
        # Slice the green which is close to paprika and in front of the paprika.
        final_mask = self.find_common_region_in_masks(green_in_front_mask, inflated_paprika_mask)
        
        imask = final_mask>0
        
        if False:
            '''
            Set trur to print the various masks.
            '''
            np.savetxt('depth_image_'+str(self.count)+ '.out', depth_image, delimiter=',')
            np.savetxt('depth_mask_'+str(self.count)+ '.out', depth_mask, delimiter=',')
            np.savetxt('final_mask_'+str(self.count)+ '.out', final_mask, delimiter=',')

        #green = np.zeros_like(img, np.uint8)
        #green[imask] = img[imask]
        
        final_mask, box = self.find_contours(final_mask)
        '''
        To print the image which masks the obstruction region with coordinates of the box enclosing it
        '''
        if DEBUG:
            cv2.imwrite(name, final_mask)
        return final_mask, box
        #return green, mask
        
        
    def find_common_region_in_masks(self, mask1, mask2):
        return np.multiply(mask1, mask2)
    
    
    def inflate_mask(self, mask, inflation_pix):
        '''
        The mask is inflated by the inflation_pix number.
        '''
        kernel = np.ones((inflation_pix, inflation_pix),np.uint8)
        dilation = cv2.dilate(mask, kernel,iterations = 1)
        return dilation
    
    
    def find_contours(self, gray):
        
        '''
        Find contours in a binary image and returns the biggest contour with coordinates of the box enclosing it.
        '''
        contours, hierarchy = cv2.findContours(gray, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        mask = np.zeros(gray.shape, np.uint8)
        largest_areas = sorted(contours, key=cv2.contourArea, reverse=True)
        cv2.drawContours(mask, largest_areas, 0, (255), 1)
        cnt = largest_areas[0]
        rect = cv2.minAreaRect(cnt)
        box = cv2.boxPoints(rect)
        box = np.int0(box)
        cv2.drawContours(mask,[box],0,(255),2)
        #print(box)
        return mask, box
    

    def _image_callback(self, msg):
        if self._msg_lock.acquire(False):
            self._last_msg = msg
            self._msg_lock.release()
            
            
    def get_center_depth(self, centers):
        depths = []
        for i in range(len(centers)):
            depths.append(self._depth_image[centers[i][0]][centers[i][1]])
        return depths 
    
            
    def _depth_image_callback(self, msg):
        if self._image_aquired:
            self._depth_image = self._cv_bridge.imgmsg_to_cv2(msg,  "passthrough")
            #np.savetxt('test.out', self._depth_image, delimiter=',')
            self._image_aquired = False
            

def main():
    rospy.init_node('mask_rcnn')
    node = MaskRCNNNode()
    node.run()

if __name__ == '__main__':
    main()
