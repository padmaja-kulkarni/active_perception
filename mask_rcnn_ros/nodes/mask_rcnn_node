#!/usr/bin/env python
import os
import threading
from Queue import Queue
import numpy as np
import skimage.io
import cv2
import random
from cv_bridge import CvBridge
import rospy
from sensor_msgs.msg import Image
from sensor_msgs.msg import RegionOfInterest
from std_msgs.msg import UInt8MultiArray

from mask_rcnn_ros import coco
from mask_rcnn_ros import utils
from mask_rcnn_ros import model as modellib
from mask_rcnn_ros import visualize
from mask_rcnn_ros.msg import Result



# Local path to trained weights file
ROS_HOME = os.environ.get('ROS_HOME', os.path.join(os.environ['HOME'], '.ros'))
COCO_MODEL_PATH = '/home/padmaja/Downloads/software/Mask_RCNN/mask_rcnn_capsicum_latest.h5' #os.path.join(ROS_HOME, 'mask_rcnn_coco.h5')

# COCO Class names
# Index of the class in the list is its ID. For example, to get ID of
# the teddy bear class, use: CLASS_NAMES.index('teddy bear')
CLASS_NAMES = ['BG', 'capsicum']
BOX_PADDING = 60

class InferenceConfig(coco.CocoConfig):
    # Set batch size to 1 since we'll be running inference on
    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1
    

class MaskRCNNNode(object):
    def __init__(self):
        self._cv_bridge = CvBridge()

        config = InferenceConfig()
        config.display()

        self._visualization = rospy.get_param('~visualization', True)

        # Create model object in inference mode.
        self._model = modellib.MaskRCNN(mode="inference", model_dir="",
                                        config=config)
        # Load weights trained on MS-COCO
        model_path = rospy.get_param('~model_path', COCO_MODEL_PATH)
        # Download COCO trained weights from Releases if needed
        if model_path == COCO_MODEL_PATH and not os.path.exists(COCO_MODEL_PATH):
        	print "loading the model"
        	utils.download_trained_weights(COCO_MODEL_PATH)
        	print "Model loaded"
        print "Modelssss loaded", model_path   
        self._model.load_weights(model_path, by_name=True) #TODO: Check if exclusion is correct as it wont recognize
        print "Weights loaded"
		
        self._class_names = rospy.get_param('~class_names', CLASS_NAMES)

        self._last_msg = None
        self._msg_lock = threading.Lock()
        self._image_aquired = False
        self._depth_image = None

        self._class_colors = visualize.random_colors(len(CLASS_NAMES))

        self._publish_rate = rospy.get_param('~publish_rate', 100)
        
        self._result_pub = rospy.Publisher('~result', Result, queue_size=1)
        self.vis_pub = rospy.Publisher('~visualization', Image, queue_size=1)
        sub = rospy.Subscriber('/camera/color/image_raw', Image,
                               self._image_callback, queue_size=1)
        depth_sub = rospy.Subscriber('/camera/depth/image_rect_raw', Image,
                               self._depth_image_callback, queue_size=1)
        self.count = 1

    def run(self):
    
        rate = rospy.Rate(self._publish_rate)
        while not rospy.is_shutdown():
            if self._msg_lock.acquire(False):
                msg = self._last_msg
                self._image_aquired = True
                self._last_msg = None
                self._msg_lock.release()
            else:
                rate.sleep()
                continue

            if msg is not None:
                np_image = self._cv_bridge.imgmsg_to_cv2(msg, 'bgr8')
                '''
                IMAGE_DIR ='/home/padmaja/Downloads/software/Mask_RCNN/datasets/capsicum/test'
                # Run detection
                
                #fake run detection on a directory
              
                file_names = next(os.walk(IMAGE_DIR))[2]
                name = random.choice(file_names)
                np_image = skimage.io.imread(os.path.join(IMAGE_DIR, name))
                print(name)
                '''
                #loaded image from a directory
                
                results = self._model.detect([np_image], verbose=0)
                result = results[0]
                #result_msg = self._build_result_msg(msg, result)
                #self._result_pub.publish(result_msg)
               
                inflated_masks = []
                if result['masks'].shape[0] > 0:
                    for i in range(result['masks'].shape[2]):
                        inflated_masks.append(self.inflate_mask(result['masks'][:, :, i], 30))
                        
                    result['rois'] = self.build_box_around_rois(result['rois'], np_image.shape)
                    # Visualize results
                    if self._visualization:
                        vis_image = self._visualize(result, np_image)
                        cv_result = np.zeros(shape=vis_image.shape, dtype=np.uint8)
                        cv2.convertScaleAbs(vis_image, cv_result)
                        image_msg = self._cv_bridge.cv2_to_imgmsg(cv_result, 'bgr8')
                        #print('\nDepths are: ', self.get_center_depth(self.get_roi_centers(result['rois'])))
                        avg_paprika_depths = self.get_avg_depth_of_mask(result['rois'], result['masks'])
                        self.vis_pub.publish(image_msg)
                        '''
                        for i, (y1, x1, y2, x2) in enumerate(result['rois']):
                            np.savetxt('test_'+str(self.count)+ '.out', self._depth_image[x1:x2, y1:y2], delimiter=',')
                            self.count = self.count + 1
                            pass
                        '''
                        
                        for i, (y1, x1, y2, x2) in enumerate(result['rois']):
                            if i ==0:
                                name = 'green_'+str(self.count)+ '.png'
                                self.find_leaves(np_image[y1:y2, x1:x2, :], name, 
                                                 avg_paprika_depths[i], self._depth_image[y1:y2, x1:x2], inflated_masks[i][y1:y2, x1:x2])
                                                 #result['masks'][y1:y2, x1:x2, i])
                                self.count = self.count + 1
            rate.sleep()

    def _build_result_msg(self, msg, result):
        result_msg = Result()
        result_msg.header = msg.header
        for i, (y1, x1, y2, x2) in enumerate(result['rois']):
            box = RegionOfInterest()
            box.x_offset = np.asscalar(x1)
            box.y_offset = np.asscalar(y1)
            box.height = np.asscalar(y2 - y1)
            box.width = np.asscalar(x2 - x1)
            result_msg.boxes.append(box)

            class_id = result['class_ids'][i]
            result_msg.class_ids.append(class_id)

            class_name = self._class_names[class_id]
            result_msg.class_names.append(class_name)

            score = result['scores'][i]
            result_msg.scores.append(score)

            mask = Image()
            mask.header = msg.header
            mask.height = result['masks'].shape[0]
            mask.width = result['masks'].shape[1]
            mask.encoding = "mono8"
            mask.is_bigendian = False
            mask.step = mask.width
            mask.data = (result['masks'][:, :, i] * 255).tobytes()
            result_msg.masks.append(mask)
        return result_msg
    
    def build_box_around_rois(self, rois, shape):
        '''
        ROIS are y1, x1, y2, x2
        '''
       
        for i in range(len(rois)):
            rois[i][0] = max(0, rois[i][0]-BOX_PADDING)
            rois[i][1] = max(0, rois[i][1]-BOX_PADDING)
            rois[i][2] = min(shape[0]-1, rois[i][2] + BOX_PADDING)
            rois[i][3] = min(shape[1]-1, rois[i][3] + BOX_PADDING)
        return rois
            
    def mask_obstacles(self, rois):
        obstacle_mask = None
        pass
        

    def _visualize(self, result, image):
        from matplotlib.backends.backend_agg import FigureCanvasAgg
        from matplotlib.figure import Figure

        fig = Figure()
        canvas = FigureCanvasAgg(fig)
        axes = fig.gca()
        visualize.display_instances(image, result['rois'], result['masks'],
                                    result['class_ids'], CLASS_NAMES,
                                    result['scores'], ax=axes,
                                    class_colors=self._class_colors)
        fig.tight_layout()
        canvas.draw()
        result = np.fromstring(canvas.tostring_rgb(), dtype='uint8')

        _, _, w, h = fig.bbox.bounds
        result = result.reshape((int(h), int(w), 3))
        return result
    
    def get_roi_centers(self, rois):
        centers = []
        for i in range(len(rois)):
            centers.append([(int((rois[i][0] + rois[i][2])/2)),
                (int((rois[i][1] + rois[i][3])/2))])
        return centers
    
    def get_avg_depth_of_mask(self, rois, masks):
        avg_depths = []
        #print(masks.shape)
        for i in range(len(rois)):
            depth_image = masks[:,:,i] * self._depth_image
            count_nonz = np.count_nonzero(depth_image)
            if count_nonz >0:
                avg_depths.append(np.sum(depth_image)/count_nonz)
        return avg_depths

    
    def find_leaves(self, img, name, avg_depth, depth_image, inflated_paprika_mask):
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        ## mask of green (36,25,25) ~ (86, 255,255)
        # mask = cv2.inRange(hsv, (36, 25, 25), (86, 255,255))
        mask = cv2.inRange(hsv, (30, 25, 15), (80, 255,255))
        ## slice the green
        depth_mask = depth_image < avg_depth
        
        
        final_mask = np.multiply(mask, depth_mask)
        
        final_mask = self.find_common_region_in_masks(final_mask, inflated_paprika_mask)
        
        imask = final_mask>0
        
        '''
        #np.savetxt('depth_image_'+str(self.count)+ '.out', depth_image, delimiter=',')
        #np.savetxt('depth_mask_'+str(self.count)+ '.out', depth_mask, delimiter=',')
        #np.savetxt('final_mask_'+str(self.count)+ '.out', final_mask, delimiter=',')
        '''
        green = np.zeros_like(img, np.uint8)
        green[imask] = img[imask]
        
        
        final_mask, box = self.find_contours(final_mask)
        '''
        To print the image.
        '''
        cv2.imwrite(name, final_mask)
        return final_mask
        #return green, mask
        
    def find_common_region_in_masks(self, mask1, mask2):
        return np.multiply(mask1, mask2)
    
    def inflate_mask(self, mask, inflation_pix):
        kernel = np.ones((inflation_pix, inflation_pix),np.uint8)
        dilation = cv2.dilate(mask, kernel,iterations = 1)
        return dilation
    
    def find_contours(self, gray):
        
        contours, hierarchy = cv2.findContours(gray, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        mask = np.zeros(gray.shape, np.uint8)
        largest_areas = sorted(contours, key=cv2.contourArea, reverse=True)
        cv2.drawContours(mask, largest_areas, 0, (255), 1)
        cnt = largest_areas[0]
        rect = cv2.minAreaRect(cnt)
        box = cv2.boxPoints(rect)
        box = np.int0(box)
        cv2.drawContours(mask,[box],0,(255),2)
        #print(box)
        return mask, box
        


    def _image_callback(self, msg):
        if self._msg_lock.acquire(False):
            self._last_msg = msg
            self._msg_lock.release()
            
    def get_center_depth(self, centers):
        depths = []
        for i in range(len(centers)):
            depths.append(self._depth_image[centers[i][0]][centers[i][1]])
        return depths 
            
    def _depth_image_callback(self, msg):
        if self._image_aquired:
            self._depth_image = self._cv_bridge.imgmsg_to_cv2(msg,  "passthrough")
            #np.savetxt('test.out', self._depth_image, delimiter=',')
            self._image_aquired = False
            

def main():
    rospy.init_node('mask_rcnn')
    node = MaskRCNNNode()
    node.run()

if __name__ == '__main__':
    main()
